{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from imp import reload\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import utils; reload(utils)\n",
    "\n",
    "from utils import *\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "embedding_size = 50\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 3\n",
    "pool_size = 4\n",
    "filters = 250\n",
    "\n",
    "# Dense\n",
    "hidden_dims = 250\n",
    "\n",
    "# Training\n",
    "batch_size = 64\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (25000, 400)\n",
      "Test data size: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print('Train data size:', x_train.shape)\n",
    "print('Test data size:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 50)           250000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 250)          37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 350,751\n",
      "Trainable params: 350,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features, \n",
    "                    embedding_size, \n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                kernel_size,\n",
    "                padding='valid',\n",
    "                activation='relu',\n",
    "                strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 269s 11ms/step - loss: 0.4392 - acc: 0.7736 - val_loss: 0.2920 - val_acc: 0.8785\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.2424 - acc: 0.9014 - val_loss: 0.2564 - val_acc: 0.8944\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 254s 10ms/step - loss: 0.1705 - acc: 0.9336 - val_loss: 0.2814 - val_acc: 0.8871\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 253s 10ms/step - loss: 0.1175 - acc: 0.9580 - val_loss: 0.2866 - val_acc: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122f1c160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_data=(x_test, y_test),\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 41s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "preds = model.predict_classes(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.891\n",
      "Test score (loss): 0.2865551609039307\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', acc)\n",
    "print('Test score (loss):', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Macro): 0.8909999370415636\n",
      "F1 Score (Micro): 0.891\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, preds, average='macro') \n",
    "f1_micro = f1_score(y_test, preds, average='micro')\n",
    "print('F1 Score (Macro):', f1_macro)\n",
    "print('F1 Score (Micro):', f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
